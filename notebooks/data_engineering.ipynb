{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bradloff/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bradloff/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Apex Import\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np \n",
    "from math import ceil, floor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCELoss, Module, Linear, AvgPool1d, MaxPool1d\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time, logging, sys, json, os\n",
    "\n",
    "%run -i \"../news-topic-cls/core/models/base.py\"\n",
    "%run -i \"../news-topic-cls/core/models/extension.py\"\n",
    "%run -i \"../news-topic-cls/core/data/data.py\"\n",
    "%run -i \"../news-topic-cls/core/utils/optim.py\"\n",
    "%run -i \"../news-topic-cls/core/utils/utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763180\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_data + \"data_lm_devex.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075770\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_data + \"data_lm_devex_mw.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_data.csv\"\n",
    "if \"test\" in filename:\n",
    "    df = pd.read_csv(path_to_data + filename).drop(labels=\"Unnamed: 0\", axis=1)\n",
    "else:\n",
    "    df = pd.read_csv(path_to_data + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, label_encoder = encode_labels(df)\n",
    "\n",
    "abbrev_mapping = get_abbreveation_mapping(label_encoder)\n",
    "df = binarize_labels(df, abbrev_mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_data + \"mongodb-dump18.json\", \"r\") as mw_export:\n",
    "    mw_export18 = json.load(mw_export)\n",
    "\n",
    "with open(path_to_data + \"mongodb-dump19.json\", \"r\") as mw_export:\n",
    "    mw_export19 = json.load(mw_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mw_export18[0][\"diffbot\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_export18[1]['development-relevance-classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for export in mw_export18:\n",
    "    if \"diffbot\" in export.keys():\n",
    "        try:\n",
    "            assert export['development-relevance-classification'][0][\"tag_name\"] == 'Humanitarian Development Related'\n",
    "        except:\n",
    "            print(\"Diffbot in Keys\")\n",
    "            print(export['development-relevance-classification'][0][\"tag_name\"])\n",
    "    else:\n",
    "        try:\n",
    "            assert export['development-relevance-classification'][0][\"tag_name\"] == 'Not Humanitarian Development Related'\n",
    "        except:\n",
    "            print(\"Diffbot not in Keys\")\n",
    "            print(export['development-relevance-classification'][0][\"tag_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_mw1819 = pd.DataFrame(columns=[\"id\", \"type\", \"text\", \"categories\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mw_articles = []\n",
    "for export in tqdm(mw_export18, total=len(mw_export18)):\n",
    "    if \"diffbot\" in export.keys() and export['development-relevance-classification'][0][\"tag_name\"] == 'Humanitarian Development Related':\n",
    "        text = export[\"diffbot\"][\"text\"]\n",
    "        all_mw_articles.append(text)\n",
    "\n",
    "for export in tqdm(mw_export19, total=len(mw_export19)):\n",
    "    if \"diffbot\" in export.keys() and export['development-relevance-classification'][0][\"tag_name\"] == 'Humanitarian Development Related':\n",
    "        text = export[\"diffbot\"][\"text\"]\n",
    "        all_mw_articles.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_mw1819.text = all_mw_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_mw1819.to_csv(\"../data/article_meltwater1819.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"roberta-base\"\n",
    "transformer = TransformerOptions(config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_confirmed = pd.read_csv(path_to_data+\"/article_confirmed.csv\")\n",
    "article_proposed = pd.read_csv(path_to_data+'/article_proposed.csv')\n",
    "article_meltwater1819 = pd.read_csv(path_to_data+'/article_meltwater1819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_development = pd.concat([article_confirmed, article_proposed, article_meltwater1819])\n",
    "articles_development.text = articles_development.text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Articles: 101015\n"
     ]
    }
   ],
   "source": [
    "print(\"Number Articles: {}\".format(len(articles_development)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_train, articles_eval = train_test_split(articles_development, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90913"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10102"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = articles_train.text.values\n",
    "text_eval = articles_eval.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30177855"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(os.path.join(path_to_data,'text_train.txt'), \"w\").write('\\n\\n'.join(text_train))\n",
    "open(os.path.join(path_to_data,\"text_eval.txt\"), \"w\").write(\"\\n\\n\".join(text_eval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis] *",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
